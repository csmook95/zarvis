import sounddevice as sd
from pyannote.audio import Pipeline
import torch
import os


# Hugging Face í† í°ì„ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
# ì´ëŠ” ì½”ë“œì— ë¯¼ê°í•œ ì •ë³´ë¥¼ ì§ì ‘ ë…¸ì¶œí•˜ì§€ ì•ŠëŠ” ì•ˆì „í•œ ë°©ë²•ì…ë‹ˆë‹¤.
HF_TOKEN = os.environ["HF_TOKEN"]
if not HF_TOKEN:
    raise ValueError(
        "Hugging Face ì¸ì¦ í† í°ì´ í•„ìš”í•©ë‹ˆë‹¤. 'HF_TOKEN' í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
    )

# ì¥ì¹˜ ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# diarization pipeline ë¡œë”© ë° ì¥ì¹˜ í• ë‹¹
print("Diarization íŒŒì´í”„ë¼ì¸ ë¡œë”© ì¤‘...")
pipeline = Pipeline.from_pretrained(
    "pyannote/speaker-diarization-3.1",
    use_auth_token=HF_TOKEN
)
pipeline.to(device)
print("íŒŒì´í”„ë¼ì¸ ë¡œë”© ì™„ë£Œ.")

# ë§ˆì´í¬ ì„¤ì •
SAMPLE_RATE = 16000  # ìƒ˜í”Œë§ ë ˆì´íŠ¸
DURATION = 10  # ì´ˆ ë‹¨ìœ„ ë²„í¼ (ì‹¤ì‹œê°„ ì²˜ë¦¬ ë‹¨ìœ„)


def record_and_diarize():
    """
    ë§ˆì´í¬ë¡œë¶€í„° ì˜¤ë””ì˜¤ë¥¼ ë…¹ìŒí•˜ê³  ì‹¤ì‹œê°„ìœ¼ë¡œ í™”ìë¥¼ ë¶„ë¦¬í•©ë‹ˆë‹¤.
    ì„ì‹œ íŒŒì¼ ìƒì„± ì—†ì´ ë©”ëª¨ë¦¬ì—ì„œ ì§ì ‘ ì²˜ë¦¬í•˜ì—¬ íš¨ìœ¨ì„±ì„ ë†’ì˜€ìŠµë‹ˆë‹¤.
    """
    print("ğŸ¤ ë§ˆì´í¬ì—ì„œ ì…ë ¥ì„ ë°›ê³  ìˆìŠµë‹ˆë‹¤ (Ctrl+Cë¡œ ì¤‘ì§€)")
    try:
        while True:
            # ì˜¤ë””ì˜¤ ë…¹ìŒ (float32 íƒ€ì…ìœ¼ë¡œ ë³€ê²½í•˜ì—¬ ëª¨ë¸ í˜¸í™˜ì„± ë° ì •ë°€ë„ í–¥ìƒ)
            print(f"âºï¸ {DURATION}ì´ˆê°„ ë…¹ìŒ ì¤‘...")
            audio_np = sd.rec(int(DURATION * SAMPLE_RATE), samplerate=SAMPLE_RATE,
                              channels=1, dtype='float32')
            sd.wait()

            # pyannote íŒŒì´í”„ë¼ì¸ ì…ë ¥ í˜•ì‹ì— ë§ê²Œ ë°ì´í„° ë³€í™˜
            # (samples, channels) -> (channels, samples)
            audio_torch = torch.from_numpy(audio_np.T).to(device)
            diarization_input = {"waveform": audio_torch,
                                 "sample_rate": SAMPLE_RATE}

            # diarization ìˆ˜í–‰ (ë©”ëª¨ë¦¬ì—ì„œ ì§ì ‘ ì²˜ë¦¬)
            print(f"ğŸ” í™”ì ë¶„ë¦¬ ì¤‘...")
            diarization = pipeline(diarization_input)

            # ê²°ê³¼ ì¶œë ¥
            print("--- í™”ì ë¶„ë¦¬ ê²°ê³¼ ---")
            for turn, _, speaker in diarization.itertracks(yield_label=True):
                print(f"[{turn.start:.2f}s - {turn.end:.2f}s] Speaker {speaker}")

    except KeyboardInterrupt:
        print("\nâœ… ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")


if __name__ == "__main__":
    record_and_diarize()
