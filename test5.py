import sounddevice as sd
import torch
import whisperx
import numpy as np
import os


# ë§ˆì´í¬ ì„¤ì •
SAMPLE_RATE = 16000  # ìƒ˜í”Œë§ ë ˆì´íŠ¸
DURATION = 3  # ì´ˆ ë‹¨ìœ„ ë²„í¼ (ì‹¤ì‹œê°„ ì²˜ë¦¬ ë‹¨ìœ„)

device = "cuda" if torch.cuda.is_available() else "cpu"
compute_type = "float16" if device == "cuda" else "int8"
batch_size = 8

# Hugging Face í† í°ì„ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
# ì´ëŠ” ì½”ë“œì— ë¯¼ê°í•œ ì •ë³´ë¥¼ ì§ì ‘ ë…¸ì¶œí•˜ì§€ ì•ŠëŠ” ì•ˆì „í•œ ë°©ë²•ì…ë‹ˆë‹¤.
HF_TOKEN = os.environ["HF_TOKEN"]
if not HF_TOKEN:
	raise ValueError(
		"Hugging Face ì¸ì¦ í† í°ì´ í•„ìš”í•©ë‹ˆë‹¤. 'HF_TOKEN' í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
	)


def record_and_diarize():
	print("ğŸ¤ ë§ˆì´í¬ì—ì„œ ì…ë ¥ì„ ë°›ê³  ìˆìŠµë‹ˆë‹¤ (Ctrl+Cë¡œ ì¤‘ì§€)")
	try:
		while True:
			# ì˜¤ë””ì˜¤ ë…¹ìŒ
			print(f"âºï¸ {DURATION }ì´ˆê°„ ë…¹ìŒ ì¤‘...")
			audio = sd.rec(int(DURATION * SAMPLE_RATE), samplerate=SAMPLE_RATE,
                            channels=1, dtype='float32')
			sd.wait()
			waveform = audio.flatten()

			# 1. ìŒì„± ì „ì‚¬
			print("1. ìŒì„± ì „ì‚¬ ì¤‘...")
			model = whisperx.load_model(
				"tiny", device, compute_type=compute_type)
			result = model.transcribe(waveform, batch_size=batch_size, language="ko")

			detected_language = result["language"]
			print(result)
			print(f"ê°ì§€ëœ ì–¸ì–´: {detected_language}")

			# 2. ë‹¨ì–´ ë ˆë²¨ ì •ë ¬
			print("2. ë‹¨ì–´ ë ˆë²¨ ì •ë ¬ ì¤‘...")
			model_a, metadata = whisperx.load_align_model(
				language_code=detected_language, device=device)
			result = whisperx.align(
				result["segments"], model_a, metadata, waveform, device, return_char_alignments=False)

			print("3. í™”ì êµ¬ë¶„ ì¤‘...")
			diarize_model = whisperx.diarize.DiarizationPipeline(
				use_auth_token=HF_TOKEN, device=device)

			# í™”ì ìˆ˜ íŒŒë¼ë¯¸í„° ì„¤ì •
			diarize_kwargs = {
				"min_speakers": 1,
				"max_speakers": 3
			}

			diarize_segments = diarize_model(waveform, **diarize_kwargs)
			result = whisperx.assign_word_speakers(
				diarize_segments, result)

			print(result)
			# for segment in result["segments"]:
			# 	speaker = segment.get("speaker", "Unknown")
			# 	start = segment["start"]
			# 	end = segment["end"]
			# 	text = segment["text"]

			# 	print(f"[{start:.2f}s - {end:.2f}s] {speaker}: {text}\n")

	except KeyboardInterrupt:
		print("\nâœ… ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")


record_and_diarize()
