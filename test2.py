import gradio as gr
import sounddevice as sd
import numpy as np
import whisperx
import tempfile
import threading
import queue
import time
from scipy.io.wavfile import write
import torch

# 3ì´ˆ ë²„í¼ ë‹¨ìœ„ (ìƒ˜í”Œë§ 16kHz)
BUFFER_DURATION = 3
SAMPLE_RATE = 16000

audio_queue = queue.Queue()
transcribed_text = ""

# WhisperX ëª¨ë¸ ë¡œë”©
device = "cuda" if torch.cuda.is_available() else "cpu"
compute_type = "float16" if device == "cuda" else "int8"
model = whisperx.load_model("medium", device=device, compute_type=compute_type)


def record_audio_loop():
	global transcribed_text

	def callback(indata, frames, time_info, status):
		audio_queue.put(indata.copy())

	with sd.InputStream(samplerate=SAMPLE_RATE, channels=1, callback=callback):
		while True:
			frames = []
			try:
				# 3ì´ˆ ë™ì•ˆ ì˜¤ë””ì˜¤ ìˆ˜ì§‘
				for _ in range(int(SAMPLE_RATE * BUFFER_DURATION / 1024)):
					frames.append(audio_queue.get(timeout=5))
				audio_data = np.concatenate(frames, axis=0)

				# WAV íŒŒì¼ë¡œ ì €ì¥
				with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmpfile:
					write(tmpfile.name, SAMPLE_RATE, audio_data)
					result = model.transcribe(tmpfile.name)
					text = result["text"]
					if text.strip():
						transcribed_text += text + "\n"

			except queue.Empty:
				continue


# ë°±ê·¸ë¼ìš´ë“œ ì“°ë ˆë“œë¡œ ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
threading.Thread(target=record_audio_loop, daemon=True).start()


def get_latest_transcription():
	return transcribed_text


with gr.Blocks() as demo:
	gr.Markdown("### ğŸ¤ WhisperX ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ (3ì´ˆ ê°„ê²©)")
	output = gr.Textbox(label="ì‹¤ì‹œê°„ ì¸ì‹ ê²°ê³¼", lines=10)

	# ì£¼ê¸°ì ìœ¼ë¡œ ê²°ê³¼ ì—…ë°ì´íŠ¸ (1ì´ˆ ê°„ê²©)
	demo.load(get_latest_transcription, outputs=output, every=1)

demo.launch()
